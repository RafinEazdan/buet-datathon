{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee12e2c",
   "metadata": {},
   "source": [
    "# Bangla Long-Form ASR Baseline\n",
    "\n",
    "Minimal baseline using **wav2vec2-large-xlsr-53** with CTC decoding.\n",
    "\n",
    "- **Input**: Long Bangla .wav files\n",
    "- **Output**: Bangla text transcription\n",
    "- **Method**: 25-second chunking, greedy CTC decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20967481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q 'nemo_toolkit[asr]'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ecf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 20:24:45.501633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1770063885.873101     102 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1770063886.009890     102 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1770063886.876627     102 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770063886.876668     102 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770063886.876670     102 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1770063886.876673     102 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Denoising enabled: True\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import librosa\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "# Configuration\n",
    "BASE_INPUT_DIR = \"/kaggle/input/dl-sprint-4-0-bengali-long-form-speech-recognition/transcription/transcription\"\n",
    "BASE_OUTPUT_DIR = \"/kaggle/working/\"\n",
    "TEST_AUDIO_DIR = os.path.join(BASE_INPUT_DIR, \"test\")\n",
    "SUBMISSION_PATH = os.path.join(BASE_OUTPUT_DIR, \"submission.csv\")\n",
    "\n",
    "MODEL_NAME = \"hishab/titu_stt_bn_fastconformer\"  # NeMo FastConformer model\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK_LENGTH_SEC = 15\n",
    "\n",
    "# Spectral Gating Configuration\n",
    "ENABLE_DENOISING = True  # Toggle denoising on/off\n",
    "NOISE_GATE_THRESHOLD_K = 2.0  # Conservative: 1.5-2.5 (higher = less aggressive)\n",
    "STFT_WIN_LENGTH_MS = 25  # ~25ms window\n",
    "STFT_HOP_LENGTH_MS = 10  # ~10ms hop\n",
    "SOFT_MASK_MIN = 0.1  # Minimum mask value (no hard zeroing)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Denoising enabled: {ENABLE_DENOISING}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8710a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processor: arijitx/wav2vec2-xls-r-300m-bengali\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a036f500f64058b70271d020f84707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7d81ffd2ea4650acfa0a394272fc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679678d51bb349ca89a5e8f454af8206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2132fe8d70745f993e34a057a26c1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bf06dd3fb048eba43b52696d418bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/309 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: arijitx/wav2vec2-xls-r-300m-bengali\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697722720a5a42a9a64b9b43cb46dcc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a40a2d4d71488d9b4df3bb8399c660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b935d19c3a487ebe3a438d68e4914b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading NeMo model: {MODEL_NAME}\")\n",
    "asr_model = nemo_asr.models.ASRModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Move model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    asr_model = asr_model.to(DEVICE)\n",
    "    print(f\"Model moved to {DEVICE}\")\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "\n",
    "asr_model.eval()\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14217f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpectralGatingDenoiser class defined\n"
     ]
    }
   ],
   "source": [
    "class SpectralGatingDenoiser:\n",
    "    \"\"\"\n",
    "    Conservative spectral gating denoiser optimized for ASR (not audio quality).\n",
    "    \n",
    "    Uses soft masking with no hard zeroing to preserve phonetic content.\n",
    "    Designed for Bangla speech where consonant articulation is critical.\n",
    "    \n",
    "    Args:\n",
    "        sample_rate: Audio sample rate (default: 16000)\n",
    "        threshold_k: Noise gate threshold multiplier (default: 2.0)\n",
    "                     Higher = more conservative (less denoising)\n",
    "        win_length_ms: STFT window length in milliseconds\n",
    "        hop_length_ms: STFT hop length in milliseconds\n",
    "        soft_mask_min: Minimum mask value to prevent hard zeroing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_rate=16000,\n",
    "        threshold_k=2.0,\n",
    "        win_length_ms=25,\n",
    "        hop_length_ms=10,\n",
    "        soft_mask_min=0.1\n",
    "    ):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.threshold_k = threshold_k\n",
    "        self.soft_mask_min = soft_mask_min\n",
    "        \n",
    "        # Convert ms to samples\n",
    "        self.win_length = int(win_length_ms * sample_rate / 1000)\n",
    "        self.hop_length = int(hop_length_ms * sample_rate / 1000)\n",
    "        \n",
    "        # Ensure win_length is valid\n",
    "        if self.win_length % 2 == 1:\n",
    "            self.win_length += 1\n",
    "            \n",
    "    def __call__(self, waveform):\n",
    "        \"\"\"\n",
    "        Apply spectral gating to waveform.\n",
    "        \n",
    "        Args:\n",
    "            waveform: numpy array or torch tensor of shape (n_samples,)\n",
    "            \n",
    "        Returns:\n",
    "            Denoised waveform as numpy array\n",
    "        \"\"\"\n",
    "        # Convert to numpy if tensor\n",
    "        if isinstance(waveform, torch.Tensor):\n",
    "            waveform = waveform.cpu().numpy()\n",
    "            \n",
    "        # Ensure mono\n",
    "        if waveform.ndim > 1:\n",
    "            waveform = waveform.mean(axis=0)\n",
    "            \n",
    "        # Skip if audio too short\n",
    "        if len(waveform) < self.win_length:\n",
    "            return waveform\n",
    "            \n",
    "        # Step 1: Compute STFT with Hann window\n",
    "        stft = librosa.stft(\n",
    "            waveform,\n",
    "            n_fft=self.win_length,\n",
    "            hop_length=self.hop_length,\n",
    "            window='hann'\n",
    "        )\n",
    "        \n",
    "        magnitude = np.abs(stft)\n",
    "        phase = np.angle(stft)\n",
    "        \n",
    "        # Step 2: Estimate noise profile from low-energy frames\n",
    "        # Use bottom 20% of frames by energy as noise estimate\n",
    "        frame_energy = np.sum(magnitude ** 2, axis=0)\n",
    "        noise_threshold_percentile = 20\n",
    "        noise_frames_mask = frame_energy <= np.percentile(frame_energy, noise_threshold_percentile)\n",
    "        \n",
    "        # Ensure we have some noise frames\n",
    "        if noise_frames_mask.sum() < 5:\n",
    "            # Fallback: use lowest 5 frames\n",
    "            noise_frame_indices = np.argsort(frame_energy)[:5]\n",
    "            noise_frames_mask = np.zeros_like(noise_frames_mask, dtype=bool)\n",
    "            noise_frames_mask[noise_frame_indices] = True\n",
    "            \n",
    "        noise_magnitude = magnitude[:, noise_frames_mask]\n",
    "        \n",
    "        # Step 3: Compute per-frequency noise statistics\n",
    "        noise_mean = np.mean(noise_magnitude, axis=1, keepdims=True)\n",
    "        noise_std = np.std(noise_magnitude, axis=1, keepdims=True)\n",
    "        \n",
    "        # Add small epsilon to prevent division by zero\n",
    "        noise_std = np.maximum(noise_std, 1e-8)\n",
    "        \n",
    "        # Step 4: Compute gating threshold\n",
    "        # threshold(f) = noise_mean(f) + k * noise_std(f)\n",
    "        threshold = noise_mean + self.threshold_k * noise_std\n",
    "        \n",
    "        # Step 5: Apply soft spectral mask\n",
    "        # Mask = min(1.0, max(soft_mask_min, magnitude / threshold))\n",
    "        mask = magnitude / (threshold + 1e-8)\n",
    "        mask = np.clip(mask, self.soft_mask_min, 1.0)\n",
    "        \n",
    "        # Apply mask to magnitude\n",
    "        denoised_magnitude = magnitude * mask\n",
    "        \n",
    "        # Step 6: Reconstruct with original phase\n",
    "        denoised_stft = denoised_magnitude * np.exp(1j * phase)\n",
    "        \n",
    "        # Inverse STFT\n",
    "        denoised_waveform = librosa.istft(\n",
    "            denoised_stft,\n",
    "            hop_length=self.hop_length,\n",
    "            window='hann',\n",
    "            length=len(waveform)  # Ensure same length as input\n",
    "        )\n",
    "        \n",
    "        return denoised_waveform\n",
    "\n",
    "\n",
    "print(\"SpectralGatingDenoiser class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9def269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASRDataset and collate_fn defined\n"
     ]
    }
   ],
   "source": [
    "class ASRDataset:\n",
    "    \"\"\"\n",
    "    Memory-safe dataset for long-form ASR with on-the-fly denoising.\n",
    "    \n",
    "    Features:\n",
    "    - Lazy audio loading (no preloading)\n",
    "    - Chunk-wise processing with temporary file creation for NeMo\n",
    "    - Optional spectral gating denoising\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        audio_paths,\n",
    "        chunk_length_sec=15,\n",
    "        sample_rate=16000,\n",
    "        denoiser=None,\n",
    "        temp_dir=\"/tmp/audio_chunks\"\n",
    "    ):\n",
    "        self.audio_paths = audio_paths\n",
    "        self.chunk_length_sec = chunk_length_sec\n",
    "        self.sample_rate = sample_rate\n",
    "        self.denoiser = denoiser\n",
    "        self.temp_dir = temp_dir\n",
    "        \n",
    "        # Create temp directory for chunks\n",
    "        os.makedirs(temp_dir, exist_ok=True)\n",
    "        \n",
    "        # Precompute chunk info for each audio file\n",
    "        self.chunk_info = []  # [(audio_idx, chunk_idx, total_chunks)]\n",
    "        \n",
    "        for audio_idx, audio_path in enumerate(audio_paths):\n",
    "            # Get audio duration without loading full file\n",
    "            info = torchaudio.info(audio_path)\n",
    "            duration_sec = info.num_frames / info.sample_rate\n",
    "            \n",
    "            # Calculate number of chunks\n",
    "            chunk_samples = int(chunk_length_sec * sample_rate)\n",
    "            total_chunks = int(np.ceil(duration_sec / chunk_length_sec))\n",
    "            \n",
    "            for chunk_idx in range(total_chunks):\n",
    "                self.chunk_info.append((audio_idx, chunk_idx, total_chunks))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.chunk_info)\n",
    "    \n",
    "    def get_chunk_path(self, audio_idx, chunk_idx):\n",
    "        \"\"\"Create a temporary chunk file and return its path.\"\"\"\n",
    "        audio_path = self.audio_paths[audio_idx]\n",
    "        \n",
    "        # Load audio chunk\n",
    "        chunk_samples = int(self.chunk_length_sec * self.sample_rate)\n",
    "        start_frame = chunk_idx * chunk_samples\n",
    "        \n",
    "        waveform, sr = torchaudio.load(\n",
    "            audio_path,\n",
    "            frame_offset=start_frame,\n",
    "            num_frames=chunk_samples\n",
    "        )\n",
    "        \n",
    "        # Convert to mono\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "            \n",
    "        # Resample if needed\n",
    "        if sr != self.sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "            \n",
    "        # Normalize\n",
    "        max_val = torch.max(torch.abs(waveform))\n",
    "        if max_val > 0:\n",
    "            waveform = waveform / max_val\n",
    "            \n",
    "        # Apply denoising if enabled\n",
    "        if self.denoiser is not None:\n",
    "            waveform_np = waveform.squeeze(0).numpy()\n",
    "            denoised_np = self.denoiser(waveform_np)\n",
    "            waveform = torch.from_numpy(denoised_np).unsqueeze(0)\n",
    "            \n",
    "        # Skip if too short\n",
    "        if waveform.shape[1] < self.sample_rate // 2:\n",
    "            return None\n",
    "            \n",
    "        # Save to temporary file\n",
    "        temp_path = os.path.join(\n",
    "            self.temp_dir, \n",
    "            f\"chunk_{audio_idx}_{chunk_idx}.wav\"\n",
    "        )\n",
    "        torchaudio.save(temp_path, waveform, self.sample_rate)\n",
    "        \n",
    "        return temp_path, audio_path, chunk_idx\n",
    "\n",
    "\n",
    "print(\"ASRDataset defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1174cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Minimal text cleanup: remove extra spaces and empty tokens.\"\"\"\n",
    "    # Remove special tokens that might appear\n",
    "    text = text.replace(\"<s>\", \"\").replace(\"</s>\", \"\")\n",
    "    text = text.replace(\"<pad>\", \"\").replace(\"<unk>\", \"\")\n",
    "    # Normalize whitespace\n",
    "    text = \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "print(\"Text cleaning function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ebc88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoiser initialized (threshold_k=2.0)\n",
      "\n",
      "Found 24 test audio files\n",
      "Dataset created: 5341 total chunks\n",
      "Processing with batch_size=4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio chunks: 100%|██████████| 1336/1336 [11:41<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 24 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize denoiser (if enabled)\n",
    "denoiser = None\n",
    "if ENABLE_DENOISING:\n",
    "    denoiser = SpectralGatingDenoiser(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        threshold_k=NOISE_GATE_THRESHOLD_K,\n",
    "        win_length_ms=STFT_WIN_LENGTH_MS,\n",
    "        hop_length_ms=STFT_HOP_LENGTH_MS,\n",
    "        soft_mask_min=SOFT_MASK_MIN\n",
    "    )\n",
    "    print(f\"Denoiser initialized (threshold_k={NOISE_GATE_THRESHOLD_K})\")\n",
    "else:\n",
    "    print(\"Denoising disabled\")\n",
    "\n",
    "# Get test audio files\n",
    "test_files = sorted(glob.glob(os.path.join(TEST_AUDIO_DIR, \"audio\", \"*.wav\")))\n",
    "print(f\"\\nFound {len(test_files)} test audio files\")\n",
    "\n",
    "# Create dataset\n",
    "dataset = ASRDataset(\n",
    "    audio_paths=test_files,\n",
    "    chunk_length_sec=CHUNK_LENGTH_SEC,\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    denoiser=denoiser\n",
    ")\n",
    "\n",
    "print(f\"Dataset created: {len(dataset)} total chunks\")\n",
    "print(f\"Processing chunks...\")\n",
    "\n",
    "# Process all chunks and aggregate by file\n",
    "from collections import defaultdict\n",
    "file_transcriptions = defaultdict(list)\n",
    "\n",
    "total_chunks = len(dataset)\n",
    "for idx in range(total_chunks):\n",
    "    result = dataset.get_chunk_path(*dataset.chunk_info[idx][:2])\n",
    "    \n",
    "    if result is None:\n",
    "        continue\n",
    "        \n",
    "    chunk_path, audio_path, chunk_idx = result\n",
    "    filename = os.path.basename(audio_path)\n",
    "    \n",
    "    try:\n",
    "        # Transcribe using NeMo (returns Hypothesis object)\n",
    "        hypothesis = asr_model.transcribe([chunk_path])[0]\n",
    "        transcription = hypothesis.text if hasattr(hypothesis, 'text') else str(hypothesis)\n",
    "        \n",
    "        if transcription.strip():\n",
    "            file_transcriptions[filename].append((chunk_idx, transcription))\n",
    "    finally:\n",
    "        # Clean up temporary chunk file\n",
    "        if os.path.exists(chunk_path):\n",
    "            os.remove(chunk_path)\n",
    "    \n",
    "    # Simple progress update\n",
    "    if (idx + 1) % 10 == 0 or (idx + 1) == total_chunks:\n",
    "        print(f\"\\rProgress: {idx + 1}/{total_chunks} chunks\", end=\"\")\n",
    "\n",
    "print()  # New line after progress\n",
    "\n",
    "# Merge transcriptions for each file\n",
    "results = []\n",
    "for filename in sorted(file_transcriptions.keys()):\n",
    "    # Sort by chunk index and merge\n",
    "    chunks = sorted(file_transcriptions[filename], key=lambda x: x[0])\n",
    "    transcriptions = [clean_text(t) for _, t in chunks]\n",
    "    full_text = \" \".join(transcriptions)\n",
    "    \n",
    "    results.append({\n",
    "        \"filename\": filename,\n",
    "        \"transcript\": full_text\n",
    "    })\n",
    "\n",
    "print(f\"\\nProcessed {len(results)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32719368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: /kaggle/working/submission.csv\n",
      "\n",
      "Submission preview (24 rows):\n",
      "       filename                                         transcript\n",
      "0  test_001.wav  এআক্সক্ষির এটেনিকেপকা আপনাকেদে ালোমানার মিডিগি...\n",
      "1  test_002.wav  মিন্তু রচ্ছাধারীনা আগিন সৈনাআমি সব দিল পমলা এব...\n",
      "2  test_003.wav  গল্পুটির সত্য আনন্দ পাবলিশাস প্রাইভেটলিমেটে কো...\n",
      "3  test_004.wav  যে কোনো জায়গায় যেতে রাতের ট্রেনি আমাদের প্সব...\n",
      "4  test_005.wav  বেচি নিবেদন ফ্রাইডেইক্লাসেক্স পরে বকিমেগ গাকছে...\n",
      "5  test_006.wav  আাদের খুব প্রন্দ হইছে আা ছেলে পছন্দমি ইলে আপনা...\n",
      "6  test_008.wav  বাদরির পোচাগর এই রকম াঙি দুগডবাটা পড সইে যাওয়...\n",
      "7  test_009.wav  দ এব দি কেকদ মৃত্যাগত গলতে সরায কেবে িতঅমিবভাজ...\n",
      "8  test_010.wav  আাই একটা তাড়াতালি ক ইে ফোন জলে আসছে আরে এতারা...\n",
      "9  test_011.wav  বেচি নিবেদন ফ্রাইডে ক্লাসেক্স ই জুই মন্টু গিয়...\n"
     ]
    }
   ],
   "source": [
    "SUBMISSION_PATH = \"/kaggle/working/\"\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame(results)\n",
    "submission_df = submission_df[[\"filename\", \"transcript\"]]\n",
    "\n",
    "# Remove .wav extension from filenames\n",
    "submission_df[\"filename\"] = submission_df[\"filename\"].str.replace(r\"\\.wav\", \"\", regex=True)\n",
    "\n",
    "# Fill any empty transcriptions\n",
    "submission_df[\"transcript\"] = submission_df[\"transcript\"].fillna(\"\")\n",
    "\n",
    "# Save submission\n",
    "submission_df.to_csv(SUBMISSION_PATH + \"submission.csv\", index=False, encoding=\"utf-8\")\n",
    "print(f\"Submission saved to: {SUBMISSION_PATH}submission.csv\")\n",
    "\n",
    "# Display preview\n",
    "print(f\"\\nSubmission preview ({len(submission_df)} rows):\")\n",
    "print(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99a153",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/kaggle/working/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_102/1035954836.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Verify submission file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUBMISSION_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Submission verification:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  - Total rows: {len(final_df)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  - Columns: {list(final_df.columns)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/kaggle/working/'"
     ]
    }
   ],
   "source": [
    "# Verify submission file\n",
    "final_df = pd.read_csv(SUBMISSION_PATH + \"submission.csv\")\n",
    "print(\"Submission verification:\")\n",
    "print(f\"  - Total rows: {len(final_df)}\")\n",
    "print(f\"  - Columns: {list(final_df.columns)}\")\n",
    "print(f\"  - Empty transcripts: {(final_df['transcript'] == '').sum()}\")\n",
    "print(f\"  - Sample filenames: {final_df['filename'].head(3).tolist()}\")\n",
    "print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
